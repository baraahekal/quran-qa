# Quran QA 2023 shared task B participation

Use the `TCE QQA2023-B demo notebook.ipynb` file to get an overview of:
1. installation
2. data download
3. faithful data generation
4. pre-training data generation
5. training and fine-tuning of a LM
6. downloading and obtaining a dump file
7. 
ðŸŽ‰ All models can be found on my [huggingface account](https://huggingface.co/MatMulMan)

**Once the training is made you will find a dump file saved!**

Something like: bert-base-arabertv02-fine-tuned-2e-05-first-827-QQA23_TaskB_qrcd_v1.2_train.zip
This is a bert-base-arabertv02 fine-tuned model with:
1. learning rate of 2e-05. 
2. first learning method.
3. A random starting seed of 827.
4. QQA23_TaskB_qrcd_v1.2_train training data is used

This dump file contains all summary results and model predictions for each sample. 
You can look at the **analysis** directory of the repo for more details.
You can group dump files into folders:
1. run **performance_analysis.py** script
2. Then run **ensemble_analysis.py** to get ensemble results from the **performance_analysis.py** script results.
3. run **generate_reports.py**  to get excel aggregated results and kernel density plots for different runs. 


## Repo Structure
```
â”œâ”€â”€ analysis
          â”œâ”€â”€ dataset_basic_analysis.py (fining basic statistics)
          â”œâ”€â”€ draw_threshold_curve.py  (effect of thresholding analysis)
          â”œâ”€â”€ ensemble_analysis.py  (script to apply ensemble on all trained models in subfolders)
          â”œâ”€â”€ generate_reports.py (writing excel reports from dump files)
          â”œâ”€â”€ no_answer_leakage_analysis.py (leakage analysis for no answer questions)
          â”œâ”€â”€ performance_analysis.py (script to analyse dump files)
â”œâ”€â”€ answer_decoding (code for answer decoding)
â”œâ”€â”€ answer_list_post_processing (code for post-processing)
â”œâ”€â”€ artifacts (generated dumps, runs and submissions (download this))
â”œâ”€â”€ configs (config scripts for transfomers)
â”œâ”€â”€ data (all generated and downloaed data is here)
â”œâ”€â”€ data_scripts (code for dataloading and generation for pretraining+ faithful splitting)
â”œâ”€â”€ ensemble (code for ensemble)
â”œâ”€â”€ metrics (code for evaluation metrics)
â”œâ”€â”€ models  (code for HF subclassed models)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ runners  (code for training script)
â”œâ”€â”€ text_processing_helpers (code for helper scripts)
â”œâ”€â”€ trainers (code for HF Trainer)
```
